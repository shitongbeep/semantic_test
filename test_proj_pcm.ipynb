{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './denserpc.label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m label_path \u001b[39m=\u001b[39m scan_path\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mvelodyne\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m'\u001b[39m)[:\u001b[39m-\u001b[39m\u001b[39m3\u001b[39m] \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     21\u001b[0m laserscan\u001b[39m.\u001b[39mopen_scan(scan_path, scan_unfold\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m---> 22\u001b[0m laserscan\u001b[39m.\u001b[39;49mopen_label(label_path)\n\u001b[1;32m     24\u001b[0m \u001b[39m# cmap = matplotlib.colormaps.get_cmap('viridis')\u001b[39;00m\n\u001b[1;32m     25\u001b[0m cmap \u001b[39m=\u001b[39m cm\u001b[39m.\u001b[39mget_cmap(\u001b[39m'\u001b[39m\u001b[39mviridis\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/autodl-nas/semantic_test/projection/laserscan.py:301\u001b[0m, in \u001b[0;36mSemLaserScan.open_label\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mFilename extension is not valid label file.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    300\u001b[0m \u001b[39m# if all goes well, open label\u001b[39;00m\n\u001b[0;32m--> 301\u001b[0m label \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mfromfile(filename, dtype\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mint32)\n\u001b[1;32m    302\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mreshape((\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m    304\u001b[0m \u001b[39m# set it\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './denserpc.label'"
     ]
    }
   ],
   "source": [
    "from projection.laserscan import LaserScan, SemLaserScan\n",
    "import yaml\n",
    "import argparse\n",
    "from torchvision.transforms import transforms\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import cm\n",
    "args = argparse.ArgumentParser(\"test\")\n",
    "args.add_argument(\"--config\", type=str, default= \"./config/semantic-kitti.yaml\")\n",
    "args = args.parse_args(args=[])\n",
    "\n",
    "with open(args.config) as config:\n",
    "    CFG = yaml.safe_load(config)\n",
    "color_dict = CFG['color_map']\n",
    "topil = transforms.ToPILImage()\n",
    "\n",
    "laserscan = SemLaserScan(color_dict, project=True)\n",
    "scan_path = \"./bin/denserpc.bin\"\n",
    "img_path = scan_path.replace('velodyne', 'image_2')[:-3] + 'png'\n",
    "label_path = scan_path.replace('velodyne', 'labels')[:-3] + 'label'\n",
    "laserscan.open_scan(scan_path, scan_unfold=False)\n",
    "laserscan.open_label(label_path)\n",
    "\n",
    "# cmap = matplotlib.colormaps.get_cmap('viridis')\n",
    "cmap = cm.get_cmap('viridis')\n",
    "sm = cm.ScalarMappable(cmap=cmap)\n",
    "color_range = sm.to_rgba(np.linspace(0,1,256), bytes=True)[:, 0:3]\n",
    "\n",
    "range_img = laserscan.proj_range\n",
    "range_img = ((range_img-range_img.min())/(range_img.max()-range_img.min())*255).astype(np.uint8)\n",
    "range_img_color = color_range[range_img].astype(np.uint8)\n",
    "\n",
    "semantic_img = topil((laserscan.proj_sem_color * 255).astype(np.uint8))\n",
    "range_img = topil(range_img_color)\n",
    "semantic_img.show()\n",
    "range_img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laserscan.open_scan(scan_path)\n",
    "laserscan.open_label(label_path)\n",
    "range_img = laserscan.proj_range\n",
    "range_img = ((range_img-range_img.min())/(range_img.max()-range_img.min())*255).astype(np.uint8)\n",
    "range_img_color = color_range[range_img].astype(np.uint8)\n",
    "\n",
    "semantic_img = topil((laserscan.proj_sem_color * 255).astype(np.uint8))\n",
    "range_img = topil(range_img_color)\n",
    "semantic_img.show()\n",
    "range_img.show('scan unfold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shitong/anaconda3/envs/penet/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mparameter\u001b[39;00m \u001b[39mimport\u001b[39;00m Parameter\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m totensor \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mToTensor()\n\u001b[1;32m      6\u001b[0m p_conv \u001b[39m=\u001b[39m proximity_conv(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m      7\u001b[0m n_conv \u001b[39m=\u001b[39m Conv2d(\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m3\u001b[39m, stride\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "from pcm.proximity_convolution import proximity_conv\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch\n",
    "totensor = transforms.ToTensor()\n",
    "p_conv = proximity_conv(1, 1, 3, stride=2)\n",
    "n_conv = Conv2d(1, 1, 3, stride=2)\n",
    "n_conv.weight = Parameter(torch.ones(1,1,3,3)/9.)\n",
    "p_conv_input = totensor(laserscan.proj_range).unsqueeze(0)\n",
    "n_conv_input = totensor(laserscan.proj_range).unsqueeze(0)\n",
    "# for i in range(4):\n",
    "#     p_conv_input = p_conv(p_conv_input)\n",
    "#     n_conv_input = n_conv(n_conv_input)\n",
    "p_conv_result = p_conv(p_conv_input)[0].permute(1,2,0).detach().numpy()[:,:,0]\n",
    "n_conv_result = n_conv(n_conv_input)[0].permute(1,2,0).detach().numpy()[:,:,0]\n",
    "p_conv_img = ((p_conv_result - p_conv_result.min())/(p_conv_result.max()-p_conv_result.min())*255).astype(np.uint8)\n",
    "n_conv_img = ((n_conv_result - n_conv_result.min())/(n_conv_result.max()-n_conv_result.min())*255).astype(np.uint8)\n",
    "p_conv_color = color_range[p_conv_img]\n",
    "n_conv_color = color_range[n_conv_img]\n",
    "\n",
    "p_conv_color = topil(p_conv_color)\n",
    "n_conv_color = topil(n_conv_color)\n",
    "p_conv_color.show()\n",
    "n_conv_color.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pcm.proximity_convolution import proximity_conv\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn.parameter import Parameter\n",
    "import torch\n",
    "totensor = transforms.ToTensor()\n",
    "p_conv = proximity_conv(3, 3, 3, stride=2)\n",
    "n_conv = Conv2d(3, 3, 3, stride=2)\n",
    "n_conv.weight = Parameter(torch.ones(3,3,3,3)/9.)\n",
    "p_conv_input = totensor(laserscan.proj_sem_color).unsqueeze(0)\n",
    "n_conv_input = totensor(laserscan.proj_sem_color).unsqueeze(0)\n",
    "# for i in range(4):\n",
    "#     p_conv_input = p_conv(p_conv_input)\n",
    "#     n_conv_input = n_conv(n_conv_input)\n",
    "p_conv_result = p_conv(p_conv_input)[0]\n",
    "n_conv_result = n_conv(n_conv_input)[0]\n",
    "\n",
    "p_conv_color = topil(p_conv_result)\n",
    "n_conv_color = topil(n_conv_result)\n",
    "p_conv_color.show()\n",
    "n_conv_color.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Oct 21 2022, 23:50:54) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1fc1e811474242f9a80f350bca525d131516aec0bc249e097c26f903f4b6c36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
